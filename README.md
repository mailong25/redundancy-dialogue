# redundancy-dialogue
Dataset and model for the paper "I already said that! Degenerating redundant questions in open-domain dialogue systems"

-------------------------- ENVIRONMENT SETUP ----------------------------------------
```
conda create -n myenv python=3.8 
source activate myenv

pip install -r requirements.txt

cd ParlAI-1.6.0 ; python setup.py develop ; cd ../
pip install torch==1.9.1+cu111 torchvision==0.10.1+cu111 torchaudio==0.9.1 -f https://download.pytorch.org/whl/torch_stable.html
wget https://storage.googleapis.com/anonymous11/ALL_DOC_DICT
wget https://storage.googleapis.com/anonymous11/ALL_MEMORY_DICT
```
### Run this command to download necessary pretrain-models and test if ParlAI is installed correctly.
```
python ParlAI-1.6.0/parlai/scripts/interactive.py -mf zoo:blenderbot2/blenderbot2_3B/model --knowledge_access_method memory_only --n_docs 5 --search_server None -dp ParlAI-1.6.0/data/
```

After that, type [EXIT] to quit the chat.

### Run this command to download MSC,BST,WOI datasets:
```
parlai display_data --task msc:Session1Self:is_convai2_session_level=False,msc:SessionBaseMsc:session_id=2,msc:SessionBaseMsc:session_id=3,msc:SessionBaseMsc:session_id=4,wizard_of_internet,blended_skill_talk -dp ./ParlAI-1.6.0/data/
```

-------------------------- DATASET GENERATION ----------------------------------------

Here is the link to download the verified dataset:
```
wget https://storage.googleapis.com/anonymous11/nrq.zip
unzip nrq.zip
cp -a nrq ./ParlAI-1.6.0/data/msc/msc/msc_dialogue/session_6

wget https://storage.googleapis.com/anonymous11/RC_data.zip
unzip RC_data.zip
```
-------------------------- TRAINING ----------------------------------------


-------------------------- REDUNDANT CLASSIFIER ----------------------------------------
```
cd Redundant_Classifier
CUDA_VISIBLE_DEVICES=0 python train.py --task_name nrq --train_file RC_data/train.json --validation_file RC_data/test.json --max_length 512 --model_name_or_path roberta-large --output_dir ./ckpt/
```

-------------------------- BB2 fine-tuning ----------------------------------------

Command to run the training:
```
sh train.sh

Before that, you must modify the following arguments defined in train.sh file:
--GPU_DEVICE: GPU device index
--METHOD: training method to use (unlikelihood,unlikelihood_aug, contrastive)
--BATCH_SIZE: batch_size (default = 4)
--OPTIM: optimizer to train the model (default = "adafactor")
--VALID_STEPS: Perform validation after a number of training steps. Checkpoints will be saved as ./checkpoints folder

Example of fine-tuning BB2 with unlikelihood:
GPU_DEVICE=0
OPTIM=adafactor
BATCH_SIZE=4
METHOD=unlikelihood
VALID_STEPS=16100
```
-----

You must manually stop the training, we suggest stopping when the number of checkpoints reaches 10.
There will be a log.txt file in each experiment_directory for you to keep track of the training and evaluation results
In our experiment, the 4th evaluation gives the best results on the validation set.

-------------------------- EVALUATION ----------------------------------------

### First, Generate 100 bot-bot conversations generated by BB2 Baseline model.
```
CUDA_VISIBLE_DEVICES=0 python self_chat.py --model ParlAI-1.6.0/data/models/blenderbot2/blenderbot2_3B/model --baseline --log self_chat_conv/baseline

Run the automatic evaluation
CUDA_VISIBLE_DEVICES=0 python eval.py --baseline
```
---------------------
After that, for each question that was generated by the Baseline model, we regenerate it with "others" models, which can be any model checkpoints from the training steps.
We recommend using our best-tunned model at ./checkpoints/best/method. If you want to test with other checkpoints, just overwrite the ./checkpoints/best/method/model with the model checkpoint that you want to evaluate

### Regenerate questions with unlikelihood training
```
CUDA_VISIBLE_DEVICES=0 python self_chat.py --model checkpoints/best/unlikelihood/model --log self_chat_conv/unlikelihood

Run the automatic evaluation
CUDA_VISIBLE_DEVICES=0 python eval.py --baseline
```

### ----- Regenerate questions with unlikelihood training -----
```
CUDA_VISIBLE_DEVICES=0 python self_chat.py --model checkpoints/best/unlikelihood/model --log self_chat_conv/unlikelihood
```
------

For others, please run:
```
CUDA_VISIBLE_DEVICES=0 python eval.py --others
```